{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "import re\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allData=pd.read_csv(\"../allData/allData.csv\")\n",
    "allData=pd.read_csv(\"allData.csv\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in allData.index:\n",
    "    allData.at[ind,\"article\"]=str(allData.at[ind,\"article\"])\n",
    "    allData.at[ind,\"title\"]=str(allData.at[ind,\"title\"])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in allData.index:\n",
    "    allData.at[ind,\"article\"]=re.sub(\"\\A\\[(.*)\\]\\Z\",r'\\1',allData.at[ind,\"article\"])\n",
    "    allData.at[ind,\"article\"]=re.sub(\"\\A'(.*)'\\Z\",r'\\1',allData.at[ind,\"article\"])\n",
    "    allData.at[ind,\"article\"]=re.sub('\\A\"(.*)\"\\Z',r'\\1',allData.at[ind,\"article\"])\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for data in allData[\"article\"]:\n",
    "    #if(re.search(\"\\A\\[.*\\]\\Z\",str(data))):\n",
    "        #print(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData=allData.dropna(axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in allData.index:\n",
    "    if(allData.at[ind,\"article\"]==\"nan\"):\n",
    "        allData=allData.drop([ind],axis=\"index\")\n",
    "allData.index=range(0,allData.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"nidaa\"]=CountVectorizer(ngram_range=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"nahdha\"]=CountVectorizer(ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"nidaa\"].fit([\"nidaa tounes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"nahdha\"].fit([\"nahdha ennahdha\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData['label'] = pd.Series( index=allData.index,dtype=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "count={}\n",
    "for row in range(0,allData.shape[0]):\n",
    "    count[\"nahdha\"]=test[\"nahdha\"].transform([allData.at[row,\"title\"]+allData.at[row,\"article\"]]).toarray().sum()\n",
    "    count[\"nidaa\"]=test[\"nidaa\"].transform([allData.at[row,\"title\"]+allData.at[row,\"article\"]]).toarray().sum()\n",
    "    if(count[\"nahdha\"]>0): allData.at[row,\"label\"]=\"nahdha\"\n",
    "    elif(count[\"nidaa\"]>0): allData.at[row,\"label\"]=\"nidaa\"\n",
    "    else : allData.at[row,\"label\"]=\"autres\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData.to_csv(\"allDataWithLabel.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
